@InProceedings{pmlr-v137-lovatto20a,
  title = 	 {Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does Not Meet Practice},
  author =       {Lovatto, \^{A}ngelo G. and Bueno, Thiago P. and Mau\'{a}, Denis D. and de Barros, Leliane N.},
  booktitle = 	 {"I Can't Believe It's Not Better!" at NeurIPS Workshops},
  year = 	 {2020},
}

@inproceedings{itervaml,
 author = {Farahmand, Amir-massoud},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Iterative Value-Aware Model Learning},
 volume = {31},
 year = {2018}
}


@InProceedings{vaml,
  title = 	 {{Value-Aware Loss Function for Model-based Reinforcement Learning}},
  author = 	 {Farahmand, Amir-massoud and Barreto, Andr{é} and Nikovski, Daniel},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2017},
}

@article{qlearning,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  year={1992},
  publisher={Springer}
}

@incollection{dqn,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NeurIPS Deep Learning Workshop},
  year = {2013}
}

@inproceedings{ddqn,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International Conference on Machine Learning},
  year={2016},
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@book{szepesvari_book,
author = {Szepesvári, Csaba},
year = {2010},
title = {Algorithms for Reinforcement Learning},
publisher={Morgan Claypool Publishers},
}

@incollection{dyna,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning Proceedings},
  pages={216--224},
  year={1990},
}

@inproceedings{pets,
 author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
 year = {2018}
}


@inproceedings{nikishin2021control,
  title={Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation},
  author={Nikishin, Evgenii and Abachi, Romina and Agarwal, Rishabh and Bacon, Pierre-Luc},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{
zhang2021learning,
title={Learning Invariant Representations for Reinforcement Learning without Reconstruction},
author={Amy Zhang and Rowan Thomas McAllister and Roberto Calandra and Yarin Gal and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  year={2011},
}

@inproceedings{ferns2004metrics,
  title={Metrics for Finite Markov Decision Processes.},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={Uncertainty in AI},
  year={2004}
}
@inproceedings{NIPS2017_ffbd6cbb,
 author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Value Prediction Network},
 year = {2017}
}

@inproceedings{10.5555/2969442.2969546,
author = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
year = {2015},
booktitle = {Advances in Neural Information Processing Systems},
}

@inproceedings{
Levine2020Prediction,
title={Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control},
author={Nir Levine and Yinlam Chow and Rui Shu and Ang Li and Mohammad Ghavamzadeh and Hung Bui},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
cui2021controlaware,
title={Control-Aware Representations for Model-based Reinforcement Learning},
author={Brandon Cui and Yinlam Chow and Mohammad Ghavamzadeh},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}
@inproceedings{grimm2021proper,
      title={Proper Value Equivalence}, 
      author={Christopher Grimm and André Barreto and Gregory Farquhar and David Silver and Satinder Singh},
      year={2021},
    booktitle = {Advances in Neural Information Processing Systems},
    pubstate={forthcoming},
    intype = {to appear in},
}


@InProceedings{lambert,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
}

@inproceedings{mbpo,
 author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {When to Trust Your Model: Model-Based Policy Optimization},
 year = {2019}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@article{moerland,
  author    = {Thomas M. Moerland and
               Joost Broekens and
               Catholijn M. Jonker},
  title     = {Model-based Reinforcement Learning: {A} Survey},
  journal   = {ArXiv},
  volume    = {abs/2006.16712},
  year      = {2020},
}

@InProceedings{lambert202objective,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
  }
  
  
@InProceedings{lovatto2020decision,
  title = 	 {Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does Not Meet Practice},
  author =       {Lovatto, \^{A}ngelo G. and Bueno, Thiago P. and Mau\'{a}, Denis D. and de Barros, Leliane N.},
  booktitle = 	 {"I Can't Believe It's Not Better!" at NeurIPS Workshops},
  year = 	 {2020},
}


@inproceedings{chow2021variatiional,
  title     = {Variational Model-based Policy Optimization},
  author    = {Chow, Yinlam and Cui, Brandon and Ryu, Moonkyung and Ghavamzadeh, Mohammad},
  booktitle = {Joint Conference on Artificial Intelligence},
  year      = {2021},
}
@article{abachi2020policy,
  author    = {Romina Abachi and
               Mohammad Ghavamzadeh and
               Amir{-}massoud Farahmand},
  title     = {Policy-Aware Model Learning for Policy Gradient Methods},
  journal   = {ArXiv},
  volume = {abs/2003.00030},
  year      = {2020},
}

@article{asadi2018equivalence,
  title={Equivalence Between Wasserstein and Value-Aware Loss for Model-based Reinforcement Learning},
  author={Asadi, Kavosh and Cater, Evan and Misra, Dipendra and Littman, Michael L},
  journal={ArXiv},
  volume = {abs/1806.01265},
  year={2018}
}

@inproceedings{grimm2020value,
 author = {Grimm, Christopher and Barreto, Andr{é} and Singh, Satinder and Silver, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {The Value Equivalence Principle for Model-Based Reinforcement Learning},
 year = {2020}
}

@inproceedings{nair2020goal,
  title={Goal-aware prediction: Learning to model what matters},
  author={Nair, Suraj and Savarese, Silvio and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  year={2020},
}


@inproceedings{ross2012agnostic,
  author={Stéphane Ross and Drew Bagnell},
  title={Agnostic System Identification for Model-Based Reinforcement Learning},
  year={2012},
  booktitle={International Conference on Machine Learning},
}

@inproceedings{
luo2018algorithmic,
title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},
author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{talvitie2017self,
  title={Self-correcting models for model-based reinforcement learning},
  author={Talvitie, Erin},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2017}
}


@inproceedings{Puterman1994MarkovDP,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Martin L. Puterman},
  booktitle={Wiley Series in Probability and Statistics},
  year={1994}
}

@inproceedings{joseph2013reinforcement,
  title={Reinforcement learning with misspecified model classes},
  author={Joseph, Joshua and Geramifard, Alborz and Roberts, John W and How, Jonathan P and Roy, Nicholas},
  booktitle={IEEE International Conference on Robotics and Automation},
  year={2013},
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  year={2013},
}

@inproceedings{schneider1997exploiting,
  title={Exploiting model uncertainty estimates for safe dynamic control learning},
  author={Schneider, Jeff G},
  booktitle={Advances in Neural Information Processing Systems},
  year={1997}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on Machine Learning},
  year={2011},
}
 @article{brockman2016openai,
  title={OpenAI gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={ArXiv},
  volume = {abs/1606.01540},
  year={2016}
} 

@Article{Pineda2021MBRL,
  author  = {Luis Pineda and Brandon Amos and Amy Zhang and Nathan O. Lambert and Roberto Calandra},
  journal = {ArXiv},
  title   = {MBRL-Lib: A Modular Library for Model-based Reinforcement Learning},
  year    = {2021},
  volume  = {abs/2104.10159}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019},
}

@article{Stone2021TheDC,
  title={The Distracting Control Suite - A Challenging Benchmark for Reinforcement Learning from Pixels},
  author={Austin Stone and Oscar Ramirez and Kurt Konolige and Rico Jonschkowski},
  journal={ArXiv},
  year={2021},
  volume={abs/2101.02722}
}

@article{lutter2021learning,
      title={Learning Dynamics Models for Model Predictive Agents}, 
      author={Michael Lutter and Leonard Hasenclever and Arunkumar Byravan and Gabriel Dulac-Arnold and Piotr Trochim and Nicolas Heess and Josh Merel and Yuval Tassa},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.14311}
}

@inproceedings{doro2020gradient,
  title={Gradient-aware model-based policy search},
  author={D'Oro, Pierluca and Metelli, Alberto Maria and Tirinzoni, Andrea and Papini, Matteo and Restelli, Marcello},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{
Hafner2020Dream,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020},
}

@book{bersekas2996neuro,
title={Neuro-Dynamic Programming},
author={Dimitri P. Bertsekas and John Tsitsiklis},
year={1996},
publisher={Athena Scientific}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@article{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  year={2010}
}

@inproceedings{gordon1995stable,
  title={Stable Function Approximation in Dynamic Programming},
  author={Gordon, Geoffrey J},
  booktitle={International Conference on Machine Learning},
  year={1995}
}

@inproceedings{AyoubJiaSzepesvariWang2020,
	author = {Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin F.},
	booktitle = {International Conference on Machine Learning},
	date-added = {2020-10-21 15:35:51 -0400},
	date-modified = {2022-05-10 19:13:50 -0400},
	title = {Model-Based Reinforcement Learning with Value-Targeted Regression},
	year = {2020}}

@inproceedings{
bjorck2022is,
title={Is High Variance Unavoidable in {RL}? A Case Study in Continuous Control},
author={Johan Bjorck and Carla P Gomes and Kilian Q Weinberger},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{bjorck2021towards,
  title={Towards deeper deep reinforcement learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@inproceedings{
zheng2023is,
title={Is Model Ensemble Necessary? Model-based {RL} via a Single Model with Lipschitz Regularized Value Function},
author={Ruijie Zheng and Xiyao Wang and Huazhe Xu and Furong Huang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}
