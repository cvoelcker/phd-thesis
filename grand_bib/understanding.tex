@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@InProceedings{lovatto2020decision,
  title = 	 {Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does Not Meet Practice},
  author =       {Lovatto, \^{A}ngelo G. and Bueno, Thiago P. and Mau\'{a}, Denis D. and de Barros, Leliane N.},
  booktitle = 	 {"I Can't Believe It's Not Better!" at NeurIPS Workshops},
  year = 	 {2020},
}

@inproceedings{itervaml,
 author = {Farahmand, Amir-massoud},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Iterative Value-Aware Model Learning},
 year = {2018}
}


@InProceedings{vaml,
  title = 	 {{Value-Aware Loss Function for Model-based Reinforcement Learning}},
  author = 	 {Farahmand, Amir-massoud and Barreto, Andr{é} and Nikovski, Daniel},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2017},
}

@article{qlearning,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  year={1992},
  publisher={Springer}
}

@incollection{dqn,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NeurIPS Deep Learning Workshop},
  year = {2013}
}

@inproceedings{ddqn,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International Conference on Machine Learning},
  year={2016},
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@book{szepesvari_book,
author = {Szepesvári, Csaba},
year = {2010},
title = {Algorithms for Reinforcement Learning},
publisher={Morgan Claypool Publishers},
}

@incollection{dyna,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning Proceedings},
  year={1990},
}

@inproceedings{pets,
 author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
 year = {2018}
}



@inproceedings{nikishin2021control,
  title={Control-oriented model-based reinforcement learning with implicit differentiation},
  author={Nikishin, Evgenii and Abachi, Romina and Agarwal, Rishabh and Bacon, Pierre-Luc},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}


@inproceedings{
zhang2021learning,
title={Learning Invariant Representations for Reinforcement Learning without Reconstruction},
author={Amy Zhang and Rowan Thomas McAllister and Roberto Calandra and Yarin Gal and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  year={2011},
}

@inproceedings{ferns2004metrics,
  title={Metrics for Finite Markov Decision Processes.},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={Uncertainty in AI},
  year={2004}
}
@inproceedings{NIPS2017_ffbd6cbb,
 author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Value Prediction Network},
 year = {2017}
}

@inproceedings{10.5555/2969442.2969546,
author = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
year = {2015},
booktitle = {Advances in Neural Information Processing Systems},
}

@inproceedings{
Levine2020Prediction,
title={Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control},
author={Nir Levine and Yinlam Chow and Rui Shu and Ang Li and Mohammad Ghavamzadeh and Hung Bui},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
cui2021controlaware,
title={Control-Aware Representations for Model-based Reinforcement Learning},
author={Brandon Cui and Yinlam Chow and Mohammad Ghavamzadeh},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  year={2020},
  publisher={Nature Publishing Group}
}
@inproceedings{grimm2021proper,
      title={Proper Value Equivalence}, 
      author={Christopher Grimm and André Barreto and Gregory Farquhar and David Silver and Satinder Singh},
      year={2021},
    booktitle = {Advances in Neural Information Processing Systems},
    pubstate={forthcoming},
    intype = {to appear in},
}


@InProceedings{lambert,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
}

@inproceedings{mbpo,
 author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {When to Trust Your Model: Model-Based Policy Optimization},
 year = {2019}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2},
  year={2002},
  publisher={Springer}
}

@article{moerland,
year = {2023},
volume = {16},
journal = {Foundations and Trends in Machine Learning},
title = {Model-based Reinforcement Learning: A Survey},
number = {1},
author = {Thomas M. Moerland and Joost Broekens and Aske Plaat and Catholijn M. Jonker}}

@InProceedings{lambert202objective,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
  }


@inproceedings{chow2021variatiional,
  title     = {Variational Model-based Policy Optimization},
  author    = {Chow, Yinlam and Cui, Brandon and Ryu, Moonkyung and Ghavamzadeh, Mohammad},
  booktitle = {Joint Conference on Artificial Intelligence},
  year      = {2021},
}
@article{abachi2020policy,
  author    = {Abachi, Romina and
            Ghavamzadeh, Mohammad and
            Farahmand, Amir-massoud},
  title     = {Policy-Aware Model Learning for Policy Gradient Methods},
  journal   = {ArXiv},
  volume = {abs/2003.00030},
  year      = {2020},
}

@article{asadi2018equivalence,
  title={Equivalence Between Wasserstein and Value-Aware Loss for Model-based Reinforcement Learning},
  author={Asadi, Kavosh and Cater, Evan and Misra, Dipendra and Littman, Michael L},
  journal={ArXiv},
  volume = {abs/1806.01265},
  year={2018}
}

@inproceedings{grimm2020value,
 author = {Grimm, Christopher and Barreto, Andr{é} and Singh, Satinder and Silver, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {The Value Equivalence Principle for Model-Based Reinforcement Learning},
 year = {2020}
}

@inproceedings{nair2020goal,
  title={Goal-aware prediction: Learning to model what matters},
  author={Nair, Suraj and Savarese, Silvio and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  year={2020},
}


@inproceedings{ross2012agnostic,
  author={Stéphane Ross and Drew Bagnell},
  title={Agnostic System Identification for Model-Based Reinforcement Learning},
  year={2012},
  booktitle={International Conference on Machine Learning},
}

@inproceedings{
luo2018algorithmic,
title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},
author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{talvitie2017self,
  title={Self-correcting models for model-based reinforcement learning},
  author={Talvitie, Erin},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2017}
}


@inproceedings{Puterman1994MarkovDP,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Martin L. Puterman},
  booktitle={Wiley Series in Probability and Statistics},
  year={1994}
}

@inproceedings{joseph2013reinforcement,
  title={Reinforcement learning with misspecified model classes},
  author={Joseph, Joshua and Geramifard, Alborz and Roberts, John W and How, Jonathan P and Roy, Nicholas},
  booktitle={IEEE International Conference on Robotics and Automation},
  year={2013},
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  year={2013},
}

@inproceedings{schneider1997exploiting,
  title={Exploiting model uncertainty estimates for safe dynamic control learning},
  author={Schneider, Jeff G},
  booktitle={Advances in Neural Information Processing Systems},
  year={1997}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on Machine Learning},
  year={2011},
}
 @article{brockman2016openai,
  title={OpenAI gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={ArXiv},
  volume = {abs/1606.01540},
  year={2016}
} 

@Article{Pineda2021MBRL,
  author  = {Luis Pineda and Brandon Amos and Amy Zhang and Nathan O. Lambert and Roberto Calandra},
  journal = {ArXiv},
  title   = {MBRL-Lib: A Modular Library for Model-based Reinforcement Learning},
  year    = {2021},
  volume  = {abs/2104.10159}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  year={2008},
  publisher={Elsevier}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019},
}

@article{Stone2021TheDC,
  title={The Distracting Control Suite - A Challenging Benchmark for Reinforcement Learning from Pixels},
  author={Austin Stone and Oscar Ramirez and Kurt Konolige and Rico Jonschkowski},
  journal={ArXiv},
  year={2021},
  volume={abs/2101.02722}
}

@article{lutter2021learning,
      title={Learning Dynamics Models for Model Predictive Agents}, 
      author={Michael Lutter and Leonard Hasenclever and Arunkumar Byravan and Gabriel Dulac-Arnold and Piotr Trochim and Nicolas Heess and Josh Merel and Yuval Tassa},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.14311}
}

@inproceedings{doro2020gradient,
  title={Gradient-aware model-based policy search},
  author={D'Oro, Pierluca and Metelli, Alberto Maria and Tirinzoni, Andrea and Papini, Matteo and Restelli, Marcello},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{
Hafner2020Dream,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020},
}

@book{bersekas2996neuro,
title={Neuro-Dynamic Programming},
author={Dimitri P. Bertsekas and John Tsitsiklis},
year={1996},
publisher={Athena Scientific}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  year={2005},
  publisher={Microtome Publishing}
}

@article{dabney2020value,
  title={The value-improvement path: Towards better representations for reinforcement learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@article{voelcker2022value,
  title={Value Gradient weighted Model-Based Reinforcement Learning},
  author={Voelcker, Claas and Liao, Victor and Garg, Animesh and Farahmand, Amir-massoud},
  journal={International Conference on Learning Representations},
  year={2022}
}

@article{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  year={2010}
}

@inproceedings{gordon1995stable,
  title={Stable Function Approximation in Dynamic Programming},
  author={Gordon, Geoffrey J},
  booktitle={International Conference on Machine Learning},
  year={1995}
}

@inproceedings{parr2008analysis,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakefield, Christopher and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  year={2008}
}

@inproceedings{amos2021model,
  title={On the model-based stochastic value gradient for continuous reinforcement learning},
  author={Amos, Brandon and Stanton, Samuel and Yarats, Denis and Wilson, Andrew Gordon},
  booktitle={Learning for Dynamics and Control},
  year={2021},
  organization={PMLR}
}

@article{Modhe2021ModelAdvantageOF,
  title={Model-Advantage Optimization for Model-Based Reinforcement Learning},
  author={Nirbhay Modhe and Harish Kamath and Dhruv Batra and A. Kalyan},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.14080}
}

@inproceedings{dadashi2019value,
  title={The value function polytope in reinforcement learning},
  author={Dadashi, Robert and Taiga, Adrien Ali and Le Roux, Nicolas and Schuurmans, Dale and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2019},
  organization={PMLR}
}

@article{
tomar2023learning,
title={Learning Representations for Pixel-based Control: What Matters and Why?},
author={Manan Tomar and Utkarsh Aashu Mishra and Amy Zhang and Matthew E. Taylor},
journal={Transactions on Machine Learning Research},
year={2023},
note={}
}

@inproceedings{
hafner2021mastering,
title={Mastering Atari with Discrete World Models},
author={Danijar Hafner and Timothy P Lillicrap and Mohammad Norouzi and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
yarats2021image,
title={Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels},
author={Denis Yarats and Ilya Kostrikov and Rob Fergus},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{fu2021learning,
  title = 	 {Learning Task Informed Abstractions},
  author =       {Fu, Xiang and Yang, Ge and Agrawal, Pulkit and Jaakkola, Tommi},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{
chen2021an,
title={An Empirical Investigation of Representation Learning for Imitation},
author={Xin Chen and Sam Toyer and Cody Wild and Scott Emmons and Ian Fischer and Kuang-Huei Lee and Neel Alex and Steven H Wang and Ping Luo and Stuart Russell and Pieter Abbeel and Rohin Shah},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
}

@article{oh2017value,
  title={Value prediction network},
  author={Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{lehnert2020successor,
  title={Successor Features Combine Elements of Model-Free and Model-based Reinforcement Learning.},
  author={Lehnert, Lucas and Littman, Michael L},
  journal={J. Mach. Learn. Res.},
  year={2020}
}

@article{ernst2005approximate,
  title={Approximate Value Iteration in the Reinforcement Learning Context. Application to Electrical Power System Control.},
  author={Ernst, Damien and Glavic, Mevludin and Geurts, Pierre and Wehenkel, Louis},
  journal={International Journal of Emerging Electric Power Systems},
  volume={3},
  number={1},
  year={2005},
  publisher={De Gruyter}
}
@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}

@article{van2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv e-prints},
  year={2018}
}

@inproceedings{zbontar2021barlow,
  title={Barlow twins: Self-supervised learning via redundancy reduction},
  author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{ibarz2021train,
  title={How to train your robot with deep reinforcement learning: lessons we have learned},
  author={Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  journal={The International Journal of Robotics Research},
  volume={40},
  number={4-5},
  year={2021},
}

@inproceedings{lyle2021effect,
  title={On the effect of auxiliary tasks on representation dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2021},
}

@article{jaderberg2016reinforcement,
  title={Reinforcement Learning with Unsupervised Auxiliary Tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={International Conference on Learning Representations},
  year={2016}
}

@article{mahadevan2007proto,
  title={Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes.},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={10},
  year={2007}
}

@article{ye2021mastering,
  title={Mastering atari games with limited data},
  author={Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{tunyasuvunakool2020,
         title = {dm\_control: Software and tasks for continuous control},
         journal = {Software Impacts},
         volume = {6},
         year = {2020},
         author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and
                   Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and
                   Timothy Lillicrap and Nicolas Heess and Yuval Tassa},
}

@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}

@article{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  journal={Advances in neural information processing systems},
  year={2015}
}

@inproceedings{lovatto2021gradient,
author = {Lovatto, \^{A}ngelo Greg\'{o}rio and Bueno, Thiago Pereira and de Barros, Leliane Nunes},
title = {Gradient Estimation in Model-Based Reinforcement Learning: A Study on Linear Quadratic Environments},
year = {2021},
publisher = {Springer-Verlag},
booktitle = {10th Brazilian Conference, BRACIS 2021},
keywords = {Machine learning, Reinforcement learning, Model-based}
}

@inproceedings{tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={International Conference on Machine Learning},
	year={2022}
}

@book{suttonbook,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
}

@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{gelada2019deepmdp,
  title={Deepmdp: Learning continuous latent space models for representation learning},
  author={Gelada, Carles and Kumar, Saurabh and Buckman, Jacob and Nachum, Ofir and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2019},
}

@article{tang2022understanding,
  title={Understanding Self-Predictive Learning for Reinforcement Learning},
  author={Tang, Yunhao and Guo, Zhaohan Daniel and Richemond, Pierre Harvey and Pires, Bernardo {\'A}vila and Chandak, Yash and Munos, R{\'e}mi and Rowland, Mark and Azar, Mohammad Gheshlaghi and Lan, Charline Le and Lyle, Clare and others},
  journal={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{
schwarzer2021dataefficient,
title={Data-Efficient Reinforcement Learning with Self-Predictive Representations},
author={Max Schwarzer and Ankesh Anand and Rishab Goel and R Devon Hjelm and Aaron Courville and Philip Bachman},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  year={2020},
}

@inproceedings{
antonoglou2022planning,
title={Planning in Stochastic Environments with a Learned Model},
author={Ioannis Antonoglou and Julian Schrittwieser and Sherjil Ozair and Thomas K Hubert and David Silver},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{Gyrfi2002ADT,
  title={A Distribution-Free Theory of Nonparametric Regression},
  author={L{\'a}szl{\'o} Gy{\"o}rfi and Michael Kohler and Adam Krzyżak and Harro Walk},
  booktitle={Springer Series in Statistics},
  year={2002}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{td3,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@article{ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={International Conference on Learning Representations},
  year={2016}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning},
  year={2014},
}


@inproceedings{
rakhsha2022operator,
title={Operator Splitting Value Iteration},
author={Rakhsha, Amin and Wang, Andrew and Ghavamzadeh, Mohammad and Farahmand, Amir-massoud},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}

@inproceedings{
abachi2022viper,
title={{VIP}er: Iterative Value-Aware Model Learning on the Value Improvement Path},
author={Abachi, Romina and Voelcker, Claas A and Garg, Animesh and Farahmand, Amir-massoud},
booktitle={Decision Awareness in Reinforcement Learning Workshop at ICML 2022},
year={2022},
}

@inproceedings{silver2017predictron,
  title={The predictron: end-to-end learning and planning},
  author={Silver, David and van Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and others},
  booktitle={International Conference on Machine Learning},
  year={2017}
}

@inproceedings{eysenbach2022mismatched,
 author = {Eysenbach, Benjamin and Khazatsky, Alexander and Levine, Sergey and Salakhutdinov, Russ R},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Mismatched No More: Joint Model-Policy Optimization for Model-Based RL},
 year = {2022}
}

@inproceedings{
ghugare2023simplifying,
title={Simplifying Model-based {RL}: Learning Representations, Latent-space Models, and Policies with One Objective},
author={Raj Ghugare and Homanga Bharadhwaj and Benjamin Eysenbach and Sergey Levine and Russ Salakhutdinov},
booktitle={International Conference on Learning Representations },
year={2023},
}


@InProceedings{pmlr-v119-abbas20a,
  title = 	 {Selective Dyna-Style Planning Under Limited Model Capacity},
  author =       {Abbas, Zaheer and Sokota, Samuel and Talvitie, Erin and White, Martha},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020},
}

@article{
kemertas2022approximate,
title={Approximate Policy Iteration with Bisimulation Metrics},
author={Mete Kemertas and Allan Douglas Jepson},
journal={Transactions on Machine Learning Research},
year={2022},
}

@inproceedings{
kemertas2021towards,
title={Towards Robust Bisimulation Metric Learning},
author={Mete Kemertas and Tristan Ty Aumentado-Armstrong},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@inproceedings{
castro2021mico,
title={{MIC}o: Improved representations via sampling-based state similarity for Markov decision processes},
author={Pablo Samuel Castro and Tyler Kastner and Prakash Panangaden and Mark Rowland},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@inproceedings{
agarwal2021contrastive,
title={Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning},
author={Rishabh Agarwal and Marlos C. Machado and Pablo Samuel Castro and Marc G Bellemare},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{lelan2022generalization,
  title = 	 { On the Generalization of Representations in Reinforcement Learning },
  author =       {Le Lan, Charline and Tu, Stephen and Oberman, Adam and Agarwal, Rishabh and Bellemare, Marc G},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year={2022}
}

@InProceedings{lelan2023bootstrapped,
  title = 	 {Bootstrapped Representations in Reinforcement Learning},
  author = {Le Lan, Charline and Tu, Stephen and Rowland, Mark and Harutyunyan, Anna and Agarwal, Rishabh and Bellemare, Marc G and Dabney, Will},
  booktitle = 	 {International Conference on Machine Learning},
  year={2023}
}

@inproceedings{li2006towards,
  author       = {Lihong Li and
                  Thomas J. Walsh and
                  Michael L. Littman},
  title        = {Towards a Unified Theory of State Abstraction for MDPs},
  booktitle    = {International Symposium on Artificial Intelligence and Mathematics},
  year         = {2006},
}


@article{bellemare2019geometric,
  title={A geometric perspective on optimal representations for reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Dadashi, Robert and Ali Taiga, Adrien and Castro, Pablo Samuel and Le Roux, Nicolas and Schuurmans, Dale and Lattimore, Tor and Lyle, Clare},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{poupart2002value,
  title={Value-directed compression of POMDPs},
  author={Poupart, Pascal and Boutilier, Craig},
  journal={Advances in neural information processing systems},
  year={2002}
}

@article{poupart2013value,
  title={Value-directed belief state approximation for POMDPs},
  author={Poupart, Pascal and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.3887},
  year={2013}
}

@article{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  journal={Advances in neural information processing systems},
  year={2018}
}


@InProceedings{modi2020sample,
  title = 	 {Sample Complexity of Reinforcement Learning using Linearly Combined Model Ensembles},
  author =       {Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2020},
}

@inproceedings{ferns2005metrics,
author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
title = {Metrics for Markov Decision Processes with Infinite State Spaces},
year = {2005},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
}

@inproceedings{
guo2022byolexplore,
title={{BYOL}-Explore: Exploration by Bootstrapped Prediction},
author={Zhaohan Daniel Guo and Shantanu Thakoor and Miruna Pislar and Bernardo Avila Pires and Florent Altch{\'e} and Corentin Tallec and Alaa Saade and Daniele Calandriello and Jean-Bastien Grill and Yunhao Tang and Michal Valko and Remi Munos and Mohammad Gheshlaghi Azar and Bilal Piot},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}@article{
hollenstein2022action,
title={Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance},
author={Jakob Hollenstein and Sayantan Auddy and Matteo Saveriano and Erwan Renaudo and Justus Piater},
journal={Transactions on Machine Learning Research},
year={2022},
}

@inproceedings{
paster2021blast,
title={{BLAST}: Latent Dynamics Models from Bootstrapping},
author={Keiran Paster and Lev E McKinney and Sheila A. McIlraith and Jimmy Ba},
booktitle={Deep RL Workshop NeurIPS 2021},
year={2021},
}


@book{BertsekasShreve1978,
	author = {Bertsekas, Dimitri P. and Shreve, Steven E.},
	publisher = {Academic Press},
	title = {Stochastic Optimal Control: The Discrete-Time Case},
	year = {1978}}


@book{Munkres2018,
	author = {Munkres, James R.},
	date-added = {2021-01-25 19:25:58 -0500},
	date-modified = {2021-01-25 19:27:15 -0500},
	edition = {2nd},
	publisher = {Pearson Modern Classic},
	title = {Topology},
	year = {2018}}

@article{garnet,
author = {T. W. Archibald and K. I. M. McKinnon and L. C. Thomas},
journal = {The Journal of the Operational Research Society},
title = {On the Generation of Markov Decision Processes},
volume = {46},
year = {1995}
}

@inproceedings{ghosh2020representations,
  title={Representations for stable off-policy reinforcement learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2020},
}

@inproceedings{le2021metrics,
  title={Metrics and continuity in reinforcement learning},
  author={Le Lan, Charline and Bellemare, Marc G and Castro, Pablo Samuel},
  booktitle={AAAI Conference on Artificial Intelligence},
  pages={8261--8269},
  year={2021}
}

@inproceedings{
farebrother2023protovalue,
title={Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks},
author={Jesse Farebrother and Joshua Greaves and Rishabh Agarwal and Charline Le Lan and Ross Goroshin and Pablo Samuel Castro and Marc G Bellemare},
booktitle={International Conference on Learning Representations },
year={2023},
}

@inproceedings{
wu2018laplacian,
title={The Laplacian in {RL}: Learning Representations with Efficient Approximations},
author={Yifan Wu and George Tucker and Ofir Nachum},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{mahadevan2005proto,
  title={Proto-value functions: Developmental reinforcement learning},
  author={Mahadevan, Sridhar},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={553--560},
  year={2005}
}

@inproceedings{petrik2007analysis,
  title={An Analysis of Laplacian Methods for Value Function Approximation in MDPs.},
  author={Petrik, Marek},
  booktitle={IJCAI},
  pages={2574--2579},
  year={2007}
}

@article{ni2024bridging,
  title={Bridging State and History Representations: Understanding Self-Predictive RL},
  author={Ni, Tianwei and Eysenbach, Benjamin and Seyedsalehi, Erfan and Ma, Michel and Gehring, Clement and Mahajan, Aditya and Bacon, Pierre-Luc},
  journal={To appear in International Conference on Learning Representations},
  year={2024}
}

@inproceedings{tang2023towards,
author = {Tang, Yunhao and Munos, R\'{e}mi},
title = {Towards a better understanding of representation dynamics under TD-learning},
year = {2023},
booktitle = {International Conference on Machine Learning},
}

@inproceedings{
lyle2022understanding,
title={Understanding and Preventing Capacity Loss in Reinforcement Learning},
author={Clare Lyle and Mark Rowland and Will Dabney},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{nikishin2022primacy,
  title={The primacy bias in deep reinforcement learning},
  author={Nikishin, Evgenii and Schwarzer, Max and D’Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  year={2022},
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
jaderberg2017reinforcement,
title={Reinforcement Learning with Unsupervised Auxiliary Tasks},
author={Max Jaderberg and Volodymyr Mnih and Wojciech Marian Czarnecki and Tom Schaul and Joel Z Leibo and David Silver and Koray Kavukcuoglu},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{behzadian2019fast,
  title={Fast feature selection for linear value function approximation},
  author={Behzadian, Bahram and Gharatappeh, Soheil and Petrik, Marek},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2019}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  year={2000},
}

@article{mahadevan2009learning,
  title={Learning representation and control in Markov decision processes: New frontiers},
  author={Mahadevan, Sridhar},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  year={2009},
}

@Article{young19minatar,
author = {{Young}, Kenny and {Tian}, Tian},
title = {MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible Reinforcement Learning Experiments},
journal = {arXiv preprint arXiv:1903.03176},
year = "2019"
}

@inproceedings{pretorius2018learning,
  title={Learning dynamics of linear denoising autoencoders},
  author={Pretorius, Arnu and Kroon, Steve and Kamper, Herman},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{saxe2014exact,
    author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
    title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
    booktitle = {International Conference on Learning Representations},
    year = 2014
}

@inproceedings{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{bao2020regularized,
  title={Regularized linear autoencoders recover the principal components, eventually},
  author={Bao, Xuchan and Lucas, James and Sachdeva, Sushant and Grosse, Roger B},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, Peter},
  journal={Neural computation},
  year={1993},
}

@article{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  journal={Advances in neural information processing systems},
  year={2017}
}

@article{izenman1975reduced,
  title={Reduced-rank regression for the multivariate linear model},
  author={Izenman, Alan Julian},
  journal={Journal of multivariate analysis},
  year={1975},
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  year={2020},
}

@article{eckart1936approximation,
  author = {Eckart, C. and Young, G.},
  journal = {Psychometrika},
  title = {The approximation of one matrix by another of lower rank},
  year = 1936
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{machado2023temporal,
  title={Temporal abstraction in reinforcement learning with the successor representation},
  author={Machado, Marlos C and Barreto, Andre and Precup, Doina and Bowling, Michael},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={80},
  pages={1--69},
  year={2023}
}

