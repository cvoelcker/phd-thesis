@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

%%%%%%%%%%%%%%%%%%%%%%%
% Classical RL
%%%%%%%%%%%%%%%%%%%%%%%

@InProceedings{thrun1993issues,
  author =       "Thrun, Sebastian and Schwartz, Anton",
  title =        "Issues in Using Function Approximation for Reinforcement Learning",
  booktitle =    "Proceedings of the 1993 Connectionist Models Summer School",
  year =         "1993",
}

@book{sutton2018introduction,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  year = {2018 }
}
@book{puterman1994markov,
author = {Puterman, Martin L.},
title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
year = {1994},
isbn = {0471619779},
publisher = {John Wiley \& Sons, Inc.},
address = {USA},
edition = {1st},
}

@article{pendrith1997estimator,
author = {Pendrith, Mark and Ryan, Malcolm},
year = {1997},
title = {Estimator Variance in Reinforcement Learning: Theoretical Problems and Practical Solutions}
}

@inproceedings{precup2001off,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
title = {Off-Policy Temporal Difference Learning with Function Approximation},
year = {2001},
booktitle = {International Conference on Machine Learning},
}

@article{mannor2007bias,
author = {Mannor, Shie and Simester, Duncan and Sun, Peng and Tsitsiklis, John N.},
title = {Bias and Variance Approximation in Value Function Estimates},
year = {2007},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {53},
number = {2},
journal = {Manage. Sci.},
month = {feb},
pages = {308â€“322},
numpages = {15},
keywords = {variance, value function, confidence interval, bias}
}

%%%%%%%%%%%%%%%%%%%%%%%
% Overestimation
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{hasselt2010double,
 author = {Hasselt, Hado van},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Double Q-learning},
 year = {2010}
}

@inproceedings{donghun2013bias,
title = "Bias-corrected Q-learning to control max-operator bias in Q-learning",
author = "Donghun Lee and Boris Defourny and Powell, {Warren Buckler}",
year = "2013",
doi = "10.1109/ADPRL.2013.6614994",
language = "English (US)",
isbn = "9781467359252",
series = "IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning, ADPRL",
pages = "93--99",
booktitle = "Proceedings of the 2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning, ADPRL 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013",
}

@inproceedings{hasselt2016deep,
author = {Hasselt, Hado van and Guez, Arthur and Silver, David},
title = {Deep reinforcement learning with double Q-Learning},
year = {2016},
booktitle = {AAAI Conference on Artificial Intelligence},
}

@inproceedings{fox2016taming,
author = {Fox, Roy and Pakman, Ari and Tishby, Naftali},
title = {Taming the noise in reinforcement learning via soft updates},
year = {2016},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
}


@InProceedings{anschel2017averaged,
  title = 	 {Averaged-{DQN}: Variance Reduction and Stabilization for Deep Reinforcement Learning},
  author =       {Oron Anschel and Nir Baram and Nahum Shimkin},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{zongzhang2017weighted,
  author    = {Zongzhang Zhang and Zhiyuan Pan and Mykel J. Kochenderfer},
  title     = {Weighted Double Q-learning},
  booktitle = {International Joint Conference on Artificial Intelligence},
  year      = {2017},
}

@inproceedings{
lan2020maxmin,
title={Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
author={Qingfeng Lan and Yangchen Pan and Alona Fyshe and Martha White},
booktitle={International Conference on Learning Representations},
year={2020},
}


@InProceedings{peer2021ensemble,
  title = 	 {Ensemble Bootstrapping for Q-Learning},
  author =       {Peer, Oren and Tessler, Chen and Merlis, Nadav and Meir, Ron},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{
liu2021regularization,
title={Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control},
author={Zhuang Liu and Xuanlin Li and Bingyi Kang and Trevor Darrell},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{kuznetsov2020controlling,
  title = 	 {Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics},
  author =       {Kuznetsov, Arsenii and Shvechikov, Pavel and Grishin, Alexander and Vetrov, Dmitry},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020},
}


@inproceedings{nauman2024overestimation,
    title={Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning},
    author={Michal Nauman and Micha{\l} Bortkiewicz and Piotr Mi{\l}o{\'s} and Tomasz Trzcinski and Mateusz Ostaszewski and Marek Cygan},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
}

@inproceedings{ball2023efficient,
author = {Ball, Philip J. and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
title = {Efficient online reinforcement learning with offline data},
year = {2023},
booktitle = {International Conference on Machine Learning},
}



@inproceedings{tarasov2023rebrac,
 author = {Tarasov, Denis and Kurenkov, Vladislav and Nikulin, Alexander and Kolesnikov, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Revisiting the Minimalist Approach to Offline Reinforcement Learning},
 year = {2023}
}

%%%%%%%%%%%%%%%%%%%%%%%
% High UTD ratios
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{fedus2020revisiting,
author = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
title = {Revisiting fundamentals of experience replay},
year = {2020},
booktitle = {International Conference on Machine Learning},
}

@InProceedings{nikishin2022primacy,
  title = 	 {The Primacy Bias in Deep Reinforcement Learning},
  author =       {Nikishin, Evgenii and Schwarzer, Max and D'Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022},
}

@inproceedings{doro2023barrier,
title={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},
author={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},
booktitle={International Conference on Learning Representations },
year={2023},
}

@InProceedings{schwarzer2023bigger,
  title = 	 {Bigger, Better, Faster: Human-level {A}tari with human-level efficiency},
  author =       {Schwarzer, Max and Obando Ceron, Johan Samir and Courville, Aaron and Bellemare, Marc G and Agarwal, Rishabh and Castro, Pablo Samuel},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023},
}

@inproceedings{kim2023resetensemble,
 author = {Kim, Woojun and Shin, Yongjae and Park, Jongeui and Sung, Youngchul},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents},
 year = {2023}
}

@inproceedings{
agarwal2021deep,
title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
author={Rishabh Agarwal and Max Schwarzer and Pablo Samuel Castro and Aaron Courville and Marc G Bellemare},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@ARTICLE{wu2020reducing,
  author={Wu, Dongming and Dong, Xingping and Shen, Jianbing and Hoi, Steven C. H.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Reducing Estimation Bias via Triplet-Average Deep Deterministic Policy Gradient}, 
  year={2020}
}

@INPROCEEDINGS{saglam2021estimation,
  author={Saglam, Baturay and Duran, Enes and Cicek, Dogan C. and Mutlu, Furkan B. and Kozat, Suleyman S.},
  booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Estimation Error Correction in Deep Reinforcement Learning for Deterministic Actor-Critic Methods}, 
  year={2021},
  volume={},
  number={},
  pages={137-144},
  keywords={Estimation error;Q-learning;Conferences;Learning (artificial intelligence);Function approximation;Task analysis;Deep reinforcement learning;deterministic actor-critic methods;estimation bias},
  doi={10.1109/ICTAI52525.2021.00027}}



%%%%%%%%%%%%%%%%%%%%%%%
% Q - Function Regularlization
%%%%%%%%%%%%%%%%%%%%%%%


@InProceedings{wang2020striving,
  title = 	 {Striving for Simplicity and Performance in Off-Policy {DRL}: Output Normalization and Non-Uniform Sampling},
  author =       {Wang, Che and Wu, Yanqiu and Vuong, Quan and Ross, Keith},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020},
}

@inproceedings{
bjorck2022is,
title={Is High Variance Unavoidable in {RL}? A Case Study in Continuous Control},
author={Johan Bjorck and Carla P Gomes and Kilian Q Weinberger},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{chen2021randomized,
  title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
  author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
  booktitle={International Conference on Learning Representations},
  year={2021},
}

@inproceedings{
hiraoka2022dropout,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{farebrother2018generalization,
  author       = {Jesse Farebrother and
                  Marlos C. Machado and
                  Michael Bowling},
  title        = {Generalization and Regularization in {DQN}},
  journal      = {CoRR},
  volume       = {abs/1810.00123},
  year         = {2018},
  eprinttype    = {arXiv},
  eprint       = {1810.00123},
  timestamp    = {Tue, 30 Oct 2018 10:49:09 +0100},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
li2023efficient,
title={Efficient Deep Reinforcement Learning Requires Regulating Overfitting},
author={Qiyang Li and Aviral Kumar and Ilya Kostrikov and Sergey Levine},
booktitle={International Conference on Learning Representations },
year={2023},
}


@InProceedings{bellemare2017distributional,
  title = 	 {A Distributional Perspective on Reinforcement Learning},
  author =       {Marc G. Bellemare and Will Dabney and R{\'e}mi Munos},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2017},
}


%%%%%%%%%%%%%%%%%%%%%%%
% Plasticity Deep RL
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
}

@InProceedings{lyle2023understanding,
  title = 	 {Understanding Plasticity in Neural Networks},
  author =       {Lyle, Clare and Zheng, Zeyu and Nikishin, Evgenii and Avila Pires, Bernardo and Pascanu, Razvan and Dabney, Will},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023},
}

@misc{abbas2023loss,
      title={Loss of Plasticity in Continual Deep Reinforcement Learning}, 
      author={Zaheer Abbas and Rosie Zhao and Joseph Modayil and Adam White and Marlos C. Machado},
      year={2023},
      eprint={2303.07507},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
yang2020harnessing,
title={Harnessing Structures for Value-Based Planning and Reinforcement Learning},
author={Yuzhe Yang and Guo Zhang and Zhi Xu and Dina Katabi},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
igl2021transient,
title={Transient Non-stationarity and Generalisation in Deep Reinforcement Learning},
author={Maximilian Igl and Gregory Farquhar and Jelena Luketina and Wendelin Boehmer and Shimon Whiteson},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{sokar2023dormant,
author = {Sokar, Ghada and Agarwal, Rishabh and Castro, Pablo Samuel and Evci, Utku},
title = {The dormant neuron phenomenon in deep reinforcement learning},
year = {2023},
booktitle = {International Conference on Machine Learning},
}

@misc{lyle2024disentangling,
      title={Disentangling the Causes of Plasticity Loss in Neural Networks}, 
      author={Clare Lyle and Zeyu Zheng and Khimya Khetarpal and Hado van Hasselt and Razvan Pascanu and James Martens and Will Dabney},
      year={2024},
      eprint={2402.18762},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


%%%%%%%%%%%%%%%%%%%%%%%
% Actor Critic Methods
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{lillicrap2016ddpg,
  added-at = {2019-07-12T20:04:55.000+0200},
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle = {International Conference on Learning Representations},
  title = {Continuous control with deep reinforcement learning.},
  year = 2016
}

@InProceedings{haarnoja2018sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2018},
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2018},
}

@InProceedings{leibfried2020mutual,
  title = 	 {Mutual-Information Regularization in Markov Decision Processes and Actor-Critic Learning},
  author =       {Leibfried, Felix and Grau-Moya, Jordi},
  booktitle = 	 {Conference on Robot Learning},
  year = 	 {2020},
}

@inproceedings{kamil2019optimistic,
 author = {Ciosek, Kamil and Vuong, Quan and Loftin, Robert and Hofmann, Katja},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Better Exploration with Optimistic Actor Critic},
 year = {2019}
}

@inproceedings{
    bhatt2024crossq,
    title={Cross$Q$: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity},
    author={Aditya Bhatt and Daniel Palenicek and Boris Belousov and Max Argus and Artemij Amiranashvili and Thomas Brox and Jan Peters},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
}

@inproceedings{janner2019mbpo,
  author = {Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine},
  title = {When to Trust Your Model: Model-Based Policy Optimization},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2019}
}


%%%%%%%%%%%%%%%%%%%%%%%
% Offline RL
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{pomerleau1988alvinn,
 author = {Pomerleau, Dean A.},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {ALVINN: An Autonomous Land Vehicle in a Neural Network},
 year = {1988}
}

@inproceedings{atkeson1997robot,
author = {Atkeson, Christopher G. and Schaal, Stefan},
title = {Robot Learning From Demonstration},
year = {1997},
booktitle = {International Conference on Machine Learning},
}

@inproceedings{fujimoto2019bcq,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019}
}

@inproceedings{fujimoto2021td3bc,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Scott Fujimoto and Shixiang Gu},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021},
}

%%%%%%%%%%%%%%%%%%%%%%%
% Model-based RL
%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{
hansen2024tdmpc,
title={{TD}-{MPC}2: Scalable, Robust World Models for Continuous Control},
author={Nicklas Hansen and Hao Su and Xiaolong Wang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

%%%%%%%%%%%%%%%%%%%%%%%
% Optimization, Standard Regularization
%%%%%%%%%%%%%%%%%%%%%%%

@inbook{rumelhart1986learning,
author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
title = {Learning internal representations by error propagation},
year = {1986},
isbn = {026268053X},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
pages = {318â€“362},
numpages = {45}
}

@inproceedings{anderson1992qlearning,
 author = {Anderson, Charles},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Q-Learning with Hidden-Unit Restarting},
 year = {1992}
}

@inproceedings{nair2010rectified,
  added-at = {2022-06-07T12:08:40.000+0200},
  author = {Nair, Vinod and Hinton, Geoffrey E},
  booktitle = {ICML 2010},
  keywords = {},
  pages = {807--814},
  title = {Rectified linear units improve restricted boltzmann machines},
  year = 2010
}


@InProceedings{sutskever2013on,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2013},
}


@InProceedings{glorot2011deep,
  title = 	 {Deep Sparse Rectifier Neural Networks},
  author = 	 {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2011},
}


@book{bishop2006pattern,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@inproceedings{krogh1991simple,
 author = {Krogh, Anders and Hertz, John},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {A Simple Weight Decay Can Improve Generalization},
 year = {1991}
}

@misc{ba2016layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{xu2019understanding,
 author = {Xu, Jingjing and Sun, Xu and Zhang, Zhiyuan and Zhao, Guangxiang and Lin, Junyang},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Understanding and Improving Layer Normalization},
 year = {2019}
}

@InProceedings{kingma2015adam,
  author    = {Kingma, Diederik and Ba, Jimmy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title     = {Adam: A Method for Stochastic Optimization},
  year      = {2015},
  address   = {San Diega, CA, USA},
  optmonth  = {12},
}

@article{srivastava14dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
}

@article{polyak1992acceleration,
author = {Polyak, B. T. and Juditsky, A. B.},
title = {Acceleration of Stochastic Approximation by Averaging},
journal = {SIAM Journal on Control and Optimization},
volume = {30},
number = {4},
pages = {838-855},
year = {1992},
doi = {10.1137/0330046},
}

@article{robbins1951stochastic,
author = {Herbert Robbins and Sutton Monro},
title = {{A Stochastic Approximation Method}},
volume = {22},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {400 -- 407},
year = {1951},
doi = {10.1214/aoms/1177729586},
}

@inproceedings{zhang2019root,
    address = "Vancouver, Canada",
    author = "Zhang, Biao and Sennrich, Rico",
    booktitle = "Advances in Neural Information Processing Systems 32",
    title = "{Root Mean Square Layer Normalization}",
    year = "2019"
}

%%%%%%%%%%%%%%%%%%%%%%%
% Software
%%%%%%%%%%%%%%%%%%%%%%%

@article{tunyasuvunakool2020dmcontrol,
         title = {dm\_control: Software and tasks for continuous control},
         journal = {Software Impacts},
         volume = {6},
         pages = {100022},
         year = {2020},
         issn = {2665-9638},
         doi = {https://doi.org/10.1016/j.simpa.2020.100022},
         author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and
                   Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and
                   Timothy Lillicrap and Nicolas Heess and Yuval Tassa},
}

@inproceedings{
asadi2023resetting,
title={Resetting the Optimizer in Deep {RL}: An Empirical Study},
author={Kavosh Asadi and Rasool Fakoor and Shoham Sabach},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@incollection{mnih2013playing,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NeurIPS Deep Learning Workshop},
  year = {2013}
}

@inproceedings{schaul2022phenomenon,
 author = {Schaul, Tom and Barreto, Andre and Quan, John and Ostrovski, Georg},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {The Phenomenon of Policy Churn},
 year = {2022}
}


@inproceedings{lee2021sunrise,
  title={Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning},
  author={Lee, Kimin and Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2020randomized,
  title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
  author={Chen, Xinyue and Wang, Che and Zhou, Zijian and Ross, Keith W},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@inproceedings{lyle2021understanding,
  title={Understanding and Preventing Capacity Loss in Reinforcement Learning},
  author={Lyle, Clare and Rowland, Mark and Dabney, Will},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{nikishin2024deep,
  title={Deep reinforcement learning with plasticity injection},
  author={Nikishin, Evgenii and Oh, Junhyuk and Ostrovski, Georg and Lyle, Clare and Pascanu, Razvan and Dabney, Will and Barreto, Andr{\'e}},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{
laidlaw2023bridging,
title={Bridging {RL} Theory and Practice with the Effective Horizon},
author={Cassidy Laidlaw and Stuart Russell and Anca Dragan},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@inproceedings{clevert2016accurate,
  author = {Clevert, Djork-ArnÃ© and Unterthiner, Thomas and Hochreiter, Sepp},
  booktitle = {International Conference on Learning Representations},
  title = {Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs).},
  year = 2016
}

@article{dabney2014adaptive,
  title={Adaptive step-sizes for reinforcement learning},
  author={Dabney, William C},
  year={2014},
journal={Thesis}
}

@inproceedings{farahmand2021pid,
  title={PID accelerated value iteration algorithm},
  author={Farahmand, Amir-massoud and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  year={2021},
  organization={PMLR}
}

@InProceedings{vieillard2020momentum,
  title = 	 {Momentum in Reinforcement Learning},
  author =       {Vieillard, Nino and Scherrer, Bruno and Pietquin, Olivier and Geist, Matthieu},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2020},
}

@article{moskovitz2021tactical,
  title={Tactical optimism and pessimism for deep reinforcement learning},
  author={Moskovitz, Ted and Parker-Holder, Jack and Pacchiano, Aldo and Arbel, Michael and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning},
  year={2001},
}

@inproceedings{NIPS1996_e0040614,
 author = {Tsitsiklis, John and Van Roy, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Analysis of Temporal-Diffference Learning with Function Approximation},
 year = {1996}
}

@article{maei2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid and Szepesvari, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={73},
  pages={1--29},
  year={2016}
}


@inproceedings{
hussing2024dissecting,
title={Dissecting Deep RL with High Update Ratios: Combatting Value Divergence},
author={Marcel Hussing and Claas A Voelcker and Igor Gilitschenski and Farahmand, Amir-massoud and Eric Eaton},
booktitle={Reinforcement Learning Conference},
year={2024},
}

@inproceedings{
voelcker2024when,
title={When does self-prediction help? Understanding Auxiliary Tasks in Reinforcement Learning},
author={Claas A Voelcker and Tyler Kastner and Igor Gilitschenski and Farahmand, Amir-massoud},
booktitle={Reinforcement Learning Conference},
year={2024},
}

@article{nauman2024bigger,
  title={Bigger, Regularized, Optimistic: scaling for compute and sample-efficient continuous control},
  author={Nauman, Michal and Ostaszewski, Mateusz and Jankowski, Krzysztof and Mi{\l}o{\'s}, Piotr and Cygan, Marek},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{tsitsiklis1996analysis,
 author = {Tsitsiklis, John and Van Roy, Benjamin},
 journal = {Advances in Neural Information Processing Systems},
 title = {Analysis of Temporal-Diffference Learning with Function Approximation},
 year = {1996}
}


@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@InProceedings{lovatto2020decision,
  title = 	 {Decision-Aware Model Learning for Actor-Critic Methods: When Theory Does Not Meet Practice},
  author =       {Lovatto, \^{A}ngelo G. and Bueno, Thiago P. and Mau\'{a}, Denis D. and de Barros, Leliane N.},
  booktitle = 	 {"I Can't Believe It's Not Better!" at NeurIPS Workshops},
  year = 	 {2020},
}

@inproceedings{itervaml,
 author = {Farahmand, Amir-massoud},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Iterative Value-Aware Model Learning},
 year = {2018}
}


@InProceedings{vaml,
  title = 	 {{Value-Aware Loss Function for Model-based Reinforcement Learning}},
  author = 	 {Farahmand, Amir-massoud and Barreto, Andr{Ã©} and Nikovski, Daniel},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2017},
}

@article{qlearning,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  year={1992},
  publisher={Springer}
}

@inproceedings{ddqn,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International Conference on Machine Learning},
  year={2016},
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@book{szepesvari_book,
author = {SzepesvÃ¡ri, Csaba},
year = {2010},
title = {Algorithms for Reinforcement Learning},
publisher={Morgan Claypool Publishers},
}

@incollection{dyna,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning Proceedings},
  year={1990},
}

@inproceedings{pets,
 author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
 year = {2018}
}



@inproceedings{nikishin2021control,
  title={Control-oriented model-based reinforcement learning with implicit differentiation},
  author={Nikishin, Evgenii and Abachi, Romina and Agarwal, Rishabh and Bacon, Pierre-Luc},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}


@inproceedings{
zhang2021learning,
title={Learning Invariant Representations for Reinforcement Learning without Reconstruction},
author={Amy Zhang and Rowan Thomas McAllister and Roberto Calandra and Yarin Gal and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ferns2011bisimulation,
  title={Bisimulation metrics for continuous Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  year={2011},
}

@inproceedings{ferns2004metrics,
  title={Metrics for Finite Markov Decision Processes.},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={Uncertainty in AI},
  year={2004}
}
@inproceedings{NIPS2017_ffbd6cbb,
 author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Value Prediction Network},
 year = {2017}
}

@inproceedings{10.5555/2969442.2969546,
author = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
year = {2015},
booktitle = {Advances in Neural Information Processing Systems},
}

@inproceedings{
Levine2020Prediction,
title={Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control},
author={Nir Levine and Yinlam Chow and Rui Shu and Ang Li and Mohammad Ghavamzadeh and Hung Bui},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
cui2021controlaware,
title={Control-Aware Representations for Model-based Reinforcement Learning},
author={Brandon Cui and Yinlam Chow and Mohammad Ghavamzadeh},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  year={2020},
  publisher={Nature Publishing Group}
}
@inproceedings{grimm2021proper,
      title={Proper Value Equivalence}, 
      author={Christopher Grimm and AndrÃ© Barreto and Gregory Farquhar and David Silver and Satinder Singh},
      year={2021},
    booktitle = {Advances in Neural Information Processing Systems},
    pubstate={forthcoming},
    intype = {to appear in},
}


@InProceedings{lambert,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
}

@inproceedings{mbpo,
 author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {When to Trust Your Model: Model-Based Policy Optimization},
 year = {2019}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2},
  year={2002},
  publisher={Springer}
}

@article{moerland,
year = {2023},
volume = {16},
journal = {Foundations and Trends in Machine Learning},
title = {Model-based Reinforcement Learning: A Survey},
number = {1},
author = {Thomas M. Moerland and Joost Broekens and Aske Plaat and Catholijn M. Jonker}}

@InProceedings{lambert202objective,
  title = 	 {Objective Mismatch in Model-based Reinforcement Learning},
  author =       {Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  booktitle = 	 {Conference on Learning for Dynamics and Control},
  year = 	 {2020},
  }


@inproceedings{chow2021variatiional,
  title     = {Variational Model-based Policy Optimization},
  author    = {Chow, Yinlam and Cui, Brandon and Ryu, Moonkyung and Ghavamzadeh, Mohammad},
  booktitle = {Joint Conference on Artificial Intelligence},
  year      = {2021},
}
@article{abachi2020policy,
  author    = {Abachi, Romina and
            Ghavamzadeh, Mohammad and
            Farahmand, Amir-massoud},
  title     = {Policy-Aware Model Learning for Policy Gradient Methods},
  journal   = {ArXiv},
  volume = {abs/2003.00030},
  year      = {2020},
}

@article{asadi2018equivalence,
  title={Equivalence Between Wasserstein and Value-Aware Loss for Model-based Reinforcement Learning},
  author={Asadi, Kavosh and Cater, Evan and Misra, Dipendra and Littman, Michael L},
  journal={ArXiv},
  volume = {abs/1806.01265},
  year={2018}
}

@inproceedings{grimm2020value,
 author = {Grimm, Christopher and Barreto, Andr{Ã©} and Singh, Satinder and Silver, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {The Value Equivalence Principle for Model-Based Reinforcement Learning},
 year = {2020}
}

@inproceedings{nair2020goal,
  title={Goal-aware prediction: Learning to model what matters},
  author={Nair, Suraj and Savarese, Silvio and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  year={2020},
}


@inproceedings{ross2012agnostic,
  author={StÃ©phane Ross and Drew Bagnell},
  title={Agnostic System Identification for Model-Based Reinforcement Learning},
  year={2012},
  booktitle={International Conference on Machine Learning},
}

@inproceedings{
luo2018algorithmic,
title={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},
author={Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{talvitie2017self,
  title={Self-correcting models for model-based reinforcement learning},
  author={Talvitie, Erin},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2017}
}


@inproceedings{Puterman1994MarkovDP,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Martin L. Puterman},
  booktitle={Wiley Series in Probability and Statistics},
  year={1994}
}

@inproceedings{joseph2013reinforcement,
  title={Reinforcement learning with misspecified model classes},
  author={Joseph, Joshua and Geramifard, Alborz and Roberts, John W and How, Jonathan P and Roy, Nicholas},
  booktitle={IEEE International Conference on Robotics and Automation},
  year={2013},
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  year={2013},
}

@inproceedings{schneider1997exploiting,
  title={Exploiting model uncertainty estimates for safe dynamic control learning},
  author={Schneider, Jeff G},
  booktitle={Advances in Neural Information Processing Systems},
  year={1997}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on Machine Learning},
  year={2011},
}
 @article{brockman2016openai,
  title={OpenAI gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={ArXiv},
  volume = {abs/1606.01540},
  year={2016}
} 

@Article{Pineda2021MBRL,
  author  = {Luis Pineda and Brandon Amos and Amy Zhang and Nathan O. Lambert and Roberto Calandra},
  journal = {ArXiv},
  title   = {MBRL-Lib: A Modular Library for Model-based Reinforcement Learning},
  year    = {2021},
  volume  = {abs/2104.10159}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  year={2008},
  publisher={Elsevier}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019},
}

@article{Stone2021TheDC,
  title={The Distracting Control Suite - A Challenging Benchmark for Reinforcement Learning from Pixels},
  author={Austin Stone and Oscar Ramirez and Kurt Konolige and Rico Jonschkowski},
  journal={ArXiv},
  year={2021},
  volume={abs/2101.02722}
}

@article{lutter2021learning,
      title={Learning Dynamics Models for Model Predictive Agents}, 
      author={Michael Lutter and Leonard Hasenclever and Arunkumar Byravan and Gabriel Dulac-Arnold and Piotr Trochim and Nicolas Heess and Josh Merel and Yuval Tassa},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.14311}
}

@inproceedings{doro2020gradient,
  title={Gradient-aware model-based policy search},
  author={D'Oro, Pierluca and Metelli, Alberto Maria and Tirinzoni, Andrea and Papini, Matteo and Restelli, Marcello},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{
Hafner2020Dream,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020},
}

@book{bersekas2996neuro,
title={Neuro-Dynamic Programming},
author={Dimitri P. Bertsekas and John Tsitsiklis},
year={1996},
publisher={Athena Scientific}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  year={2005},
  publisher={Microtome Publishing}
}

@article{dabney2020value,
  title={The value-improvement path: Towards better representations for reinforcement learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@article{voelcker2022value,
  title={Value Gradient weighted Model-Based Reinforcement Learning},
  author={Voelcker, Claas A and Liao, Victor and Garg, Animesh and Farahmand, Amir-massoud},
  journal={International Conference on Learning Representations},
  year={2022}
}

@article{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  year={2010}
}

@inproceedings{gordon1995stable,
  title={Stable Function Approximation in Dynamic Programming},
  author={Gordon, Geoffrey J},
  booktitle={International Conference on Machine Learning},
  year={1995}
}

@inproceedings{parr2008analysis,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakefield, Christopher and Littman, Michael L},
  booktitle={International conference on Machine learning},
  year={2008}
}

@inproceedings{amos2021model,
  title={On the model-based stochastic value gradient for continuous reinforcement learning},
  author={Amos, Brandon and Stanton, Samuel and Yarats, Denis and Wilson, Andrew Gordon},
  booktitle={Learning for Dynamics and Control},
  year={2021},
  organization={PMLR}
}

@article{Modhe2021ModelAdvantageOF,
  title={Model-Advantage Optimization for Model-Based Reinforcement Learning},
  author={Nirbhay Modhe and Harish Kamath and Dhruv Batra and A. Kalyan},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.14080}
}

@inproceedings{dadashi2019value,
  title={The value function polytope in reinforcement learning},
  author={Dadashi, Robert and Taiga, Adrien Ali and Le Roux, Nicolas and Schuurmans, Dale and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2019},
  organization={PMLR}
}

@article{
tomar2023learning,
title={Learning Representations for Pixel-based Control: What Matters and Why?},
author={Manan Tomar and Utkarsh Aashu Mishra and Amy Zhang and Matthew E. Taylor},
journal={Transactions on Machine Learning Research},
year={2023},
note={}
}

@inproceedings{
hafner2021mastering,
title={Mastering Atari with Discrete World Models},
author={Danijar Hafner and Timothy P Lillicrap and Mohammad Norouzi and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
yarats2021image,
title={Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels},
author={Denis Yarats and Ilya Kostrikov and Rob Fergus},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{fu2021learning,
  title = 	 {Learning Task Informed Abstractions},
  author =       {Fu, Xiang and Yang, Ge and Agrawal, Pulkit and Jaakkola, Tommi},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{
chen2021an,
title={An Empirical Investigation of Representation Learning for Imitation},
author={Xin Chen and Sam Toyer and Cody Wild and Scott Emmons and Ian Fischer and Kuang-Huei Lee and Neel Alex and Steven H Wang and Ping Luo and Stuart Russell and Pieter Abbeel and Rohin Shah},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
}

@article{oh2017value,
  title={Value prediction network},
  author={Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{lehnert2020successor,
  title={Successor Features Combine Elements of Model-Free and Model-based Reinforcement Learning.},
  author={Lehnert, Lucas and Littman, Michael L},
  journal={J. Mach. Learn. Res.},
  year={2020}
}

@article{ernst2005approximate,
  title={Approximate Value Iteration in the Reinforcement Learning Context. Application to Electrical Power System Control.},
  author={Ernst, Damien and Glavic, Mevludin and Geurts, Pierre and Wehenkel, Louis},
  journal={International Journal of Emerging Electric Power Systems},
  volume={3},
  number={1},
  year={2005},
  publisher={De Gruyter}
}
@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}

@article{van2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv e-prints},
  year={2018}
}

@inproceedings{zbontar2021barlow,
  title={Barlow twins: Self-supervised learning via redundancy reduction},
  author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{ibarz2021train,
  title={How to train your robot with deep reinforcement learning: lessons we have learned},
  author={Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  journal={The International Journal of Robotics Research},
  volume={40},
  number={4-5},
  year={2021},
}

@inproceedings{lyle2021effect,
  title={On the effect of auxiliary tasks on representation dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2021},
}

@article{jaderberg2016reinforcement,
  title={Reinforcement Learning with Unsupervised Auxiliary Tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={International Conference on Learning Representations},
  year={2016}
}

@article{mahadevan2007proto,
  title={Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes.},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={10},
  year={2007}
}

@article{ye2021mastering,
  title={Mastering atari games with limited data},
  author={Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{tunyasuvunakool2020,
         title = {dm\_control: Software and tasks for continuous control},
         journal = {Software Impacts},
         volume = {6},
         year = {2020},
         author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and
                   Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and
                   Timothy Lillicrap and Nicolas Heess and Yuval Tassa},
}

@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}

@article{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  journal={Advances in neural information processing systems},
  year={2015}
}

@inproceedings{lovatto2021gradient,
author = {Lovatto, \^{A}ngelo Greg\'{o}rio and Bueno, Thiago Pereira and de Barros, Leliane Nunes},
title = {Gradient Estimation in Model-Based Reinforcement Learning: A Study on Linear Quadratic Environments},
year = {2021},
publisher = {Springer-Verlag},
booktitle = {10th Brazilian Conference, BRACIS 2021},
keywords = {Machine learning, Reinforcement learning, Model-based}
}

@inproceedings{tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={International Conference on Machine Learning},
	year={2022}
}

@book{suttonbook,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA},
}

@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{gelada2019deepmdp,
  title={Deepmdp: Learning continuous latent space models for representation learning},
  author={Gelada, Carles and Kumar, Saurabh and Buckman, Jacob and Nachum, Ofir and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2019},
}

@article{tang2022understanding,
  title={Understanding Self-Predictive Learning for Reinforcement Learning},
  author={Tang, Yunhao and Guo, Zhaohan Daniel and Richemond, Pierre Harvey and Pires, Bernardo {\'A}vila and Chandak, Yash and Munos, R{\'e}mi and Rowland, Mark and Azar, Mohammad Gheshlaghi and Lan, Charline Le and Lyle, Clare and others},
  journal={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{
schwarzer2021dataefficient,
title={Data-Efficient Reinforcement Learning with Self-Predictive Representations},
author={Max Schwarzer and Ankesh Anand and Rishab Goel and R Devon Hjelm and Aaron Courville and Philip Bachman},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  year={2020},
}

@inproceedings{
antonoglou2022planning,
title={Planning in Stochastic Environments with a Learned Model},
author={Ioannis Antonoglou and Julian Schrittwieser and Sherjil Ozair and Thomas K Hubert and David Silver},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{Gyrfi2002ADT,
  title={A Distribution-Free Theory of Nonparametric Regression},
  author={L{\'a}szl{\'o} Gy{\"o}rfi and Michael Kohler and Adam KrzyÅ¼ak and Harro Walk},
  booktitle={Springer Series in Statistics},
  year={2002}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}


@article{ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={International Conference on Learning Representations},
  year={2016}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning},
  year={2014},
}


@inproceedings{
rakhsha2022operator,
title={Operator Splitting Value Iteration},
author={Rakhsha, Amin and Wang, Andrew and Ghavamzadeh, Mohammad and Farahmand, Amir-massoud},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}

@inproceedings{
abachi2022viper,
title={{VIP}er: Iterative Value-Aware Model Learning on the Value Improvement Path},
author={Abachi, Romina and Voelcker, Claas A and Garg, Animesh and Farahmand, Amir-massoud},
booktitle={Decision Awareness in Reinforcement Learning Workshop at ICML 2022},
year={2022},
}

@inproceedings{silver2017predictron,
  title={The predictron: end-to-end learning and planning},
  author={Silver, David and van Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and others},
  booktitle={International Conference on Machine Learning},
  year={2017}
}

@inproceedings{eysenbach2022mismatched,
 author = {Eysenbach, Benjamin and Khazatsky, Alexander and Levine, Sergey and Salakhutdinov, Russ R},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Mismatched No More: Joint Model-Policy Optimization for Model-Based RL},
 year = {2022}
}

@inproceedings{
ghugare2023simplifying,
title={Simplifying Model-based {RL}: Learning Representations, Latent-space Models, and Policies with One Objective},
author={Raj Ghugare and Homanga Bharadhwaj and Benjamin Eysenbach and Sergey Levine and Russ Salakhutdinov},
booktitle={International Conference on Learning Representations },
year={2023},
}


@InProceedings{pmlr-v119-abbas20a,
  title = 	 {Selective Dyna-Style Planning Under Limited Model Capacity},
  author =       {Abbas, Zaheer and Sokota, Samuel and Talvitie, Erin and White, Martha},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020},
}

@article{
kemertas2022approximate,
title={Approximate Policy Iteration with Bisimulation Metrics},
author={Mete Kemertas and Allan Douglas Jepson},
journal={Transactions on Machine Learning Research},
year={2022},
}

@inproceedings{
kemertas2021towards,
title={Towards Robust Bisimulation Metric Learning},
author={Mete Kemertas and Tristan Ty Aumentado-Armstrong},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@inproceedings{
castro2021mico,
title={{MIC}o: Improved representations via sampling-based state similarity for Markov decision processes},
author={Pablo Samuel Castro and Tyler Kastner and Prakash Panangaden and Mark Rowland},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}

@inproceedings{
agarwal2021contrastive,
title={Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning},
author={Rishabh Agarwal and Marlos C. Machado and Pablo Samuel Castro and Marc G Bellemare},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{lelan2022generalization,
  title = 	 { On the Generalization of Representations in Reinforcement Learning },
  author =       {Le Lan, Charline and Tu, Stephen and Oberman, Adam and Agarwal, Rishabh and Bellemare, Marc G},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year={2022}
}

@InProceedings{lelan2023bootstrapped,
  title = 	 {Bootstrapped Representations in Reinforcement Learning},
  author = {Le Lan, Charline and Tu, Stephen and Rowland, Mark and Harutyunyan, Anna and Agarwal, Rishabh and Bellemare, Marc G and Dabney, Will},
  booktitle = 	 {International Conference on Machine Learning},
  year={2023}
}

@inproceedings{li2006towards,
  author       = {Lihong Li and
                  Thomas J. Walsh and
                  Michael L. Littman},
  title        = {Towards a Unified Theory of State Abstraction for MDPs},
  booktitle    = {International Symposium on Artificial Intelligence and Mathematics},
  year         = {2006},
}


@article{bellemare2019geometric,
  title={A geometric perspective on optimal representations for reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Dadashi, Robert and Ali Taiga, Adrien and Castro, Pablo Samuel and Le Roux, Nicolas and Schuurmans, Dale and Lattimore, Tor and Lyle, Clare},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{poupart2002value,
  title={Value-directed compression of POMDPs},
  author={Poupart, Pascal and Boutilier, Craig},
  journal={Advances in neural information processing systems},
  year={2002}
}

@article{poupart2013value,
  title={Value-directed belief state approximation for POMDPs},
  author={Poupart, Pascal and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.3887},
  year={2013}
}

@article{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  journal={Advances in neural information processing systems},
  year={2018}
}


@InProceedings{modi2020sample,
  title = 	 {Sample Complexity of Reinforcement Learning using Linearly Combined Model Ensembles},
  author =       {Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  year = 	 {2020},
}

@inproceedings{ferns2005metrics,
author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
title = {Metrics for Markov Decision Processes with Infinite State Spaces},
year = {2005},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
}

@inproceedings{
guo2022byolexplore,
title={{BYOL}-Explore: Exploration by Bootstrapped Prediction},
author={Zhaohan Daniel Guo and Shantanu Thakoor and Miruna Pislar and Bernardo Avila Pires and Florent Altch{\'e} and Corentin Tallec and Alaa Saade and Daniele Calandriello and Jean-Bastien Grill and Yunhao Tang and Michal Valko and Remi Munos and Mohammad Gheshlaghi Azar and Bilal Piot},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}@article{
hollenstein2022action,
title={Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance},
author={Jakob Hollenstein and Sayantan Auddy and Matteo Saveriano and Erwan Renaudo and Justus Piater},
journal={Transactions on Machine Learning Research},
year={2022},
}

@inproceedings{
paster2021blast,
title={{BLAST}: Latent Dynamics Models from Bootstrapping},
author={Keiran Paster and Lev E McKinney and Sheila A. McIlraith and Jimmy Ba},
booktitle={Deep RL Workshop NeurIPS 2021},
year={2021},
}


@book{BertsekasShreve1978,
	author = {Bertsekas, Dimitri P. and Shreve, Steven E.},
	publisher = {Academic Press},
	title = {Stochastic Optimal Control: The Discrete-Time Case},
	year = {1978}}


@book{Munkres2018,
	author = {Munkres, James R.},
	date-added = {2021-01-25 19:25:58 -0500},
	date-modified = {2021-01-25 19:27:15 -0500},
	edition = {2nd},
	publisher = {Pearson Modern Classic},
	title = {Topology},
	year = {2018}}

@article{garnet,
author = {T. W. Archibald and K. I. M. McKinnon and L. C. Thomas},
journal = {The Journal of the Operational Research Society},
title = {On the Generation of Markov Decision Processes},
volume = {46},
year = {1995}
}

@inproceedings{ghosh2020representations,
  title={Representations for stable off-policy reinforcement learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  booktitle={International Conference on Machine Learning},
  year={2020},
}

@inproceedings{le2021metrics,
  title={Metrics and continuity in reinforcement learning},
  author={Le Lan, Charline and Bellemare, Marc G and Castro, Pablo Samuel},
  booktitle={AAAI Conference on Artificial Intelligence},
  pages={8261--8269},
  year={2021}
}

@inproceedings{
farebrother2023protovalue,
title={Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks},
author={Jesse Farebrother and Joshua Greaves and Rishabh Agarwal and Charline Le Lan and Ross Goroshin and Pablo Samuel Castro and Marc G Bellemare},
booktitle={International Conference on Learning Representations },
year={2023},
}

@inproceedings{
wu2018laplacian,
title={The Laplacian in {RL}: Learning Representations with Efficient Approximations},
author={Yifan Wu and George Tucker and Ofir Nachum},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{mahadevan2005proto,
  title={Proto-value functions: Developmental reinforcement learning},
  author={Mahadevan, Sridhar},
  booktitle={International Conference on Machine learning},
  year={2005}
}

@inproceedings{petrik2007analysis,
  title={An Analysis of Laplacian Methods for Value Function Approximation in MDPs.},
  author={Petrik, Marek},
  booktitle={IJCAI},
  pages={2574--2579},
  year={2007}
}

@article{ni2024bridging,
  title={Bridging State and History Representations: Understanding Self-Predictive RL},
  author={Ni, Tianwei and Eysenbach, Benjamin and Seyedsalehi, Erfan and Ma, Michel and Gehring, Clement and Mahajan, Aditya and Bacon, Pierre-Luc},
  journal={To appear in International Conference on Learning Representations},
  year={2024}
}

@inproceedings{tang2023towards,
author = {Tang, Yunhao and Munos, R\'{e}mi},
title = {Towards a better understanding of representation dynamics under TD-learning},
year = {2023},
booktitle = {International Conference on Machine Learning},
}

@inproceedings{
lyle2022understanding,
title={Understanding and Preventing Capacity Loss in Reinforcement Learning},
author={Clare Lyle and Mark Rowland and Will Dabney},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{
jaderberg2017reinforcement,
title={Reinforcement Learning with Unsupervised Auxiliary Tasks},
author={Max Jaderberg and Volodymyr Mnih and Wojciech Marian Czarnecki and Tom Schaul and Joel Z Leibo and David Silver and Koray Kavukcuoglu},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{behzadian2019fast,
  title={Fast feature selection for linear value function approximation},
  author={Behzadian, Bahram and Gharatappeh, Soheil and Petrik, Marek},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2019}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  year={2000},
}

@article{mahadevan2009learning,
  title={Learning representation and control in Markov decision processes: New frontiers},
  author={Mahadevan, Sridhar},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  year={2009},
}

@Article{young19minatar,
author = {{Young}, Kenny and {Tian}, Tian},
title = {MinAtar: An Atari-Inspired Testbed for Thorough and Reproducible Reinforcement Learning Experiments},
journal = {arXiv preprint arXiv:1903.03176},
year = "2019"
}

@inproceedings{pretorius2018learning,
  title={Learning dynamics of linear denoising autoencoders},
  author={Pretorius, Arnu and Kroon, Steve and Kamper, Herman},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{saxe2014exact,
    author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
    title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
    booktitle = {International Conference on Learning Representations},
    year = 2014
}

@inproceedings{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{bao2020regularized,
  title={Regularized linear autoencoders recover the principal components, eventually},
  author={Bao, Xuchan and Lucas, James and Sachdeva, Sushant and Grosse, Roger B},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@conference{chan2020measuring,
  title = {Measuring the Reliability of Reinforcement Learning Algorithms},
  author = {Stephanie Chan and Sam Fishman and John Canny and Anoop Korattikara and Sergio Guadarrama},
  booktitle = {International Conference on Learning Representations},
  year = 2020,
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, Peter},
  journal={Neural computation},
  year={1993},
}

@article{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  journal={Advances in neural information processing systems},
  year={2017}
}

@article{izenman1975reduced,
  title={Reduced-rank regression for the multivariate linear model},
  author={Izenman, Alan Julian},
  journal={Journal of multivariate analysis},
  year={1975},
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  year={2020},
}

@article{eckart1936approximation,
  author = {Eckart, C. and Young, G.},
  journal = {Psychometrika},
  title = {The approximation of one matrix by another of lower rank},
  year = 1936
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{machado2023temporal,
  title={Temporal abstraction in reinforcement learning with the successor representation},
  author={Machado, Marlos C and Barreto, Andre and Precup, Doina and Bowling, Michael},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={80},
  pages={1--69},
  year={2023}
}


@InProceedings{zhao2023simplified,
  title = 	 {Simplified Temporal Consistency Reinforcement Learning},
  author =       {Zhao, Yi and Zhao, Wenshuai and Boney, Rinu and Kannala, Juho and Pajarinen, Joni},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023},
}

@article{fujimoto2024sale,
  title={For sale: State-action representation learning for deep reinforcement learning},
  author={Fujimoto, Scott and Chang, Wei-Di and Smith, Edward and Gu, Shixiang Shane and Precup, Doina and Meger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{
lavoie2023simplicial,
title={Simplicial Embeddings in Self-Supervised Learning and Downstream Classification},
author={Samuel Lavoie and Christos Tsirigotis and Max Schwarzer and Ankit Vani and Michael Noukhovitch and Kenji Kawaguchi and Aaron Courville},
booktitle={International Conference on Learning Representations },
year={2023},
}

@inproceedings{
farebrother2024stop,
title={Stop Regressing: Training Value Functions via Classification for Scalable Deep {RL}},
author={Jesse Farebrother and Jordi Orbay and Quan Vuong and Adrien Ali Taiga and Yevgen Chebotar and Ted Xiao and Alex Irpan and Sergey Levine and Pablo Samuel Castro and Aleksandra Faust and Aviral Kumar and Rishabh Agarwal},
booktitle={International Conference on Machine Learning},
year={2024},
}

@inproceedings{
madry2018towards,
title={Towards Deep Learning Models Resistant to Adversarial Attacks},
author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
booktitle={International Conference on Learning Representations},
year={2018},
}
@article{ostrovski2021difficulty,
  title={The difficulty of passive learning in deep reinforcement learning},
  author={Ostrovski, Georg and Castro, Pablo Samuel and Dabney, Will},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{fujimoto2022should,
  title={Why should i trust you, bellman? the bellman error is a poor replacement for value error},
  author={Fujimoto, Scott and Meger, David and Precup, Doina and Nachum, Ofir and Gu, Shixiang Shane},
  journal={International Conference on Machine Learning},
  year={2022}
}


@InProceedings{hansen2022temporal,
  title = 	 {Temporal Difference Learning for Model Predictive Control},
  author =       {Hansen, Nicklas A and Su, Hao and Wang, Xiaolong},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022},
}

@inproceedings{
agarwal2022reincarnating,
title={Reincarnating Reinforcement Learning: Reusing Prior Computation to Accelerate Progress},
author={Rishabh Agarwal and Max Schwarzer and Pablo Samuel Castro and Aaron Courville and Marc G Bellemare},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}

@inproceedings{
tirumala2024replay,
title={Replay across Experiments: A Natural Extension of Off-Policy {RL}},
author={Dhruva Tirumala and Thomas Lampe and Jose Enrique Chen and Tuomas Haarnoja and Sandy Huang and Guy Lever and Ben Moran and Tim Hertweck and Leonard Hasenclever and Martin Riedmiller and Nicolas Heess and Markus Wulfmeier},
booktitle={International Conference on Learning Representations},
year={2024},
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  year={1988},
  publisher={Springer}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine learning proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

@article{lu2024synthetic,
  title={Synthetic experience replay},
  author={Lu, Cong and Ball, Philip and Teh, Yee Whye and Parker-Holder, Jack},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{kastner2023distributional,
  title={Distributional model equivalence for risk-sensitive reinforcement learning},
  author={Kastner, Tyler and Erdogdu, Murat A and Farahmand, Amir-massoud},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{
wei2024a,
title={A Unified View on Solving Objective Mismatch in Model-Based Reinforcement Learning},
author={Ran Wei and Nathan Lambert and Anthony D McDonald and Alfredo Garcia and Roberto Calandra},
journal={Transactions on Machine Learning Research},
year={2024},
}

@article{talvitie2024bounding,
    title={Bounding-Box Inference for Error-Aware Model-Based Reinforcement Learning},
    author={Talvitie, Erin J and Shao, Zilei and Li, Huiying and Hu, Jinghan and Boerma, Jacob and Zhao, Rory and Wang, Xintong},
    journal={Reinforcement Learning Journal},
    year={2024}
}

@inproceedings{
Pan2020Frequencybased,
title={Frequency-based Search-control in Dyna},
author={Yangchen Pan and Jincheng Mei and Farahmand, Amir-massoud },
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{pan2019hill,
author = {Pan, Yangchen and Yao, Hengshuai and Farahmand, Amir-massoud and White, Martha},
title = {Hill climbing on value estimates for search-control in Dyna},
year = {2019},
booktitle = {International Joint Conference on Artificial Intelligence},
}

@article{misra2020mish,
  title={Mish: A self regularized non-monotonic activation function},
  author={Misra, Diganta},
  journal={British Machine Vision Conference},
  year={2020}
}

@inproceedings{xu2024drm,
    title={DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization},
    author={Guowei Xu and Ruijie Zheng and Yongyuan Liang and Xiyao Wang and Zhecheng Yuan and Tianying Ji and Yu Luo and Xiaoyu Liu and Jiaxin Yuan and Pu Hua and Shuzhen Li and Yanjie Ze and Hal Daum{\'e} III and Furong Huang and Huazhe Xu},
    booktitle={International Conference on Learning Representations},
    year={2024},
}

@inproceedings{lee2023plastic,
     author = {Lee, Hojoon and Cho, Hanseul and KIM, HYUNSEUNG and GWAK, DAEHOON and Kim, Joonkee and Choo, Jaegul and Yun, Se-Young and Yun, Chulhee},
     booktitle = {Advances in Neural Information Processing Systems},
     title = {PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning},
     year = {2023}
}

@inproceedings{elsayed2024weightclipping,
  title={Weight clipping for deep continual and reinforcement learning},
  author={Elsayed, Mohamed and Lan, Qingfeng and Lyle, Clare and Mahmood, A Rupam},
  booktitle={Reinforcement Learning Conference},
  year={2024}
}


@InProceedings{lee2024slow,
  title = 	 {Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks},
  author =       {Lee, Hojoon and Cho, Hyeonseo and Kim, Hyunseung and Kim, Donghu and Min, Dugki and Choo, Jaegul and Lyle, Clare},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2024},
}

@inproceedings{eaton2023replicable,
    title={Replicable Reinforcement Learning},
    author={Eric Eaton and Marcel Hussing and Michael Kearns and Jessica Sorrell},
    booktitle={Conference on Neural Information Processing Systems},
    year={2023},
}

@InProceedings{vietri2020private,
  title = 	 {Private Reinforcement Learning with {PAC} and Regret Guarantees},
  author =       {Vietri, Giuseppe and Balle, Borja and Krishnamurthy, Akshay and Wu, Steven},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  year = 	 {2020},
}


@InProceedings{pinto2017robust,
  title = 	 {Robust Adversarial Reinforcement Learning},
  author =       {Lerrel Pinto and James Davidson and Rahul Sukthankar and Abhinav Gupta},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@article{ceron2024consistency,
    title={On the consistency of hyper-parameter selection in value-based deep reinforcement learning},
    author={Ceron, Johan Samir Obando and Ara{\'{u}}jo, Jo{\~{a}}o Guilherme Madeira and Courville, Aaron and Castro, Pablo Samuel},
    journal={Reinforcement Learning Journal},
year={2024}
}

@article{patterson2024cross,
    title={Cross-environment Hyperparameter Tuning for Reinforcement Learning},
    author={Patterson, Andrew and Neumann, Samuel and Kumaraswamy, Raksha and White, Martha and White, Adam},
    journal={Reinforcement Learning Journal},
    year={2024}
}

@article{nilim2005robust,
	title        = {Robust Control of Markov Decision Processes with Uncertain Transition Matrices.},
	author       = {Nilim, Arnab and Ghaoui, Laurent El},
	year         = 2005,
	journal      = {Operations Research},
}

@article{iyengar2005robust,
	title        = {Robust Dynamic Programming},
	author       = {Garud N. Iyengar},
	year         = 2005,
	journal      = {Mathematics of Operations Research},
}

@article{wiesemann2013robust,
	title        = {Robust Markov Decision Processes},
	author       = {Wolfram Wiesemann and Daniel Kuhn and BreÃ§ Rustem},
	year         = 2013,
	journal      = {Mathematics of Operations Research},
	publisher    = {INFORMS},
	volume       = 38,
	number       = 1,
	pages        = {153--183}
}

@InProceedings{kuang2023variance,
  title = 	 {Variance Control for Distributional Reinforcement Learning},
  author =       {Kuang, Qi and Zhu, Zhoufan and Zhang, Liwen and Zhou, Fan},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  year = 	 {2023},
}

@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning},
  year={2019},
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning: State-of-the-art},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}


